services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        WITH_CUDA: ${WITH_CUDA:-true}
        CUDA_ARCHS: ${CUDA_ARCHS:-120}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    container_name: ask_llm_app
    environment:
      # Database connection (external postgres.home server)
      ASK_LLM_POSTGRES_HOST: ${POSTGRES_HOST:-postgres.home}
      ASK_LLM_POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      ASK_LLM_POSTGRES_DATABASE: ${POSTGRES_DB:-askllm}
      ASK_LLM_POSTGRES_USER: ${POSTGRES_USER:-askllm}
      ASK_LLM_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-askllm_mem0ry}

      # Service configuration
      ASK_LLM_MEMORY_SERVER_HOST: 0.0.0.0
      ASK_LLM_MEMORY_SERVER_PORT: 8001
      ASK_LLM_SERVICE_HOST: 0.0.0.0
      ASK_LLM_SERVICE_PORT: 8642

      # Memory server URL (internal)
      ASK_LLM_MEMORY_SERVER_URL: http://127.0.0.1:8001

      # API Keys (pass through from host .env)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      TAVILY_API_KEY: ${TAVILY_API_KEY:-}

      # User and bot settings
      ASK_LLM_DEFAULT_USER: ${DEFAULT_USER:-nick}
      ASK_LLM_DEFAULT_BOT: ${ASK_LLM_DEFAULT_BOT:-nova}
      ASK_LLM_DEFAULT_MODEL_ALIAS: ${ASK_LLM_DEFAULT_MODEL_ALIAS:-gpt-5.2-2025-12-11}

      # Logging
      ASK_LLM_LOG_PREFIX: ${ASK_LLM_LOG_PREFIX:-docker}
      ASK_LLM_DEBUG_TURN_LOG: ${ASK_LLM_DEBUG_TURN_LOG:-true}
      ASK_LLM_LOG_DIR: /app/.logs
    ports:
      - "${MCP_PORT:-8001}:8001"
      - "${SERVICE_PORT:-8642}:8642"
    volumes:
      # Mount host config directory to avoid duplication
      - ${HOME}/.config/ask-llm:/root/.config/ask-llm
      # Mount logs directory
      - ./.logs:/app/.logs
      # Optional: mount local models
      - ${MODELS_PATH:-./models}:/app/models
    restart: unless-stopped
    stdin_open: true
    tty: true
